---
layout: post
title: å¤§æ¨¡å‹ï¼Œå°æ¢ç´¢ â€”â€” åœ¨ 16G çš„ AMD ä¸Šæå¾®è°ƒæœ‰å¤šä½œæ­»ï¼Ÿï¼ˆå…¥å‘ç¯‡ï¼‰
toc:  true
author: å°ç‹—å±
tags: [GPT-Explore]
css:
  - "assets/markdown.css"
---

å¾®ä¿¡å…¬ä¼—å·å†…å®¹åœ°å€: https://mp.weixin.qq.com/s/JsGoshZJKnbd-tdIA8B9KA

> é¢„è®­ç»ƒå’Œå¾®è°ƒ: é¢„è®­ç»ƒç±»æ¯”äºé€šè¯†æ•™è‚²ï¼Œä¾§é‡é€šç”¨èƒ½åŠ›ï¼Œæé«˜æ¨¡å‹çš„ä¸Šé™ï¼Œå¦‚èƒ½æ›´å¥½åœ°**å­¦ä¹ **ï¼›å¾®è°ƒç±»æ¯”äºä¸“ä¸šæ•™è‚²ï¼Œä¾§é‡ç»†èŠ‚èƒ½åŠ›ï¼Œå¼¥è¡¥æ¨¡å‹çš„ä¸‹é™ï¼Œå¦‚èƒ½æ›´å¥½åœ°**å¹²æ´»**ã€‚

ç»§"ç†Ÿç»ƒ"æŒæ¡äº†å¤§æ¨¡å‹**éƒ¨ç½²**æŠ€æœ¯åï¼Œå°ç‹—å±å·²ç»æ‘†çƒ‚æ•°æ—¥ï¼Œç›´åˆ°æŸå¤©é‚®ç®±æ”¶åˆ°äº†ä¸€æ¡ä¿¡æ¯:

![](https://files.mdnice.com/user/44560/a77c005c-c981-44c1-9237-eff2f92f2c16.png)

æ—¢ç„¶ç®—åŠ›å·²ç»åˆ°è´¦ï¼Œé‚£å°±å†æ¢ç´¢ä¸€æ³¢ï¼Œå°è¯•ä¸€ä¸‹å¾®è°ƒå§ã€‚

é‰´äºç¯‡å¹…è¾ƒé•¿ï¼Œåœ¨æ­¤å…ˆè¯´ç»“è®º: åœ¨å¤±è´¥äº†ä¸€ä¸‡æ¬¡ä¹‹å ğŸ˜‚ï¼Œä¸ªäººè§‰å¾—ï¼Œ<font color='red'>ä¸‹ä¸€æ¬¡ä¸€å®šèƒ½æˆåŠŸ</font>ï¼

![](https://files.mdnice.com/user/44560/87b4d930-a4fb-4b1c-8141-3857b36753bf.png)

# ç¯å¢ƒèƒŒæ™¯

å…ˆæ¥æ¢³ç†ä¸€ä¸‹ï¼Œç›®å‰ä¸ºæ­¢çš„åŸºæœ¬ç¯å¢ƒ:

- ç®—åŠ›å’Œå­˜å‚¨: è¶…ç®—äº’è”ç½‘å¹³å°ï¼Œ<font color='red'>é NVIDIA çš„ GPU</font>ï¼ˆæ¨æµ‹æ˜¯ <font color='red'>AMD-ROCm</font>ï¼‰ï¼Œä»¥åŠç‰¹æ®Šç‰ˆæœ¬çš„ pytorchã€‚
- æ–‡ç”Ÿæ–‡å¤§æ¨¡å‹: Baichuan2ï¼Œä¸”ä¹‹å‰å·²ç»åœ¨å¹³å°ä¸Šéƒ¨ç½²äº† Baichuan2-7B-Chat
  - Github åœ°å€: https://github.com/baichuan-inc/Baichuan2
  - Hugging Face åœ°å€: https://hf-mirror.com/baichuan-inc/Baichuan2-7B-Chat
- æ–‡ç”Ÿæ–‡æ•°æ®é›†: ç›®å‰æš‚æœªæ¶‰åŠï¼Œä¸€èˆ¬åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œè¯„æµ‹é›†ã€‚

# å¾®è°ƒç†è®º

å¤§æ¨¡å‹å¾®è°ƒï¼ˆFine-tuningï¼‰æ˜¯æŒ‡åœ¨å·²ç»é¢„è®­ç»ƒå¥½çš„å¤§å‹è¯­è¨€æ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨ç‰¹å®šçš„æ•°æ®é›†è¿›è¡Œè¿›ä¸€æ­¥çš„è®­ç»ƒï¼Œä»¥ä½¿æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸã€‚é€šä¿—çš„ç†è§£ï¼Œå¾®è°ƒå°±æ˜¯<font color='red'>è®©é€šç”¨çš„å¤§æ¨¡å‹å…·å¤‡æ›´å¼ºçš„ä¸“ä¸šèƒ½åŠ›</font>ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œä¸è®­ç»ƒç±»ä¼¼ï¼Œå¾®è°ƒçš„æ“ä½œæ­¥éª¤åŒ…æ‹¬:

1. ç›®æ ‡æ•°æ®é›†ï¼Œå¾®è°ƒéœ€è¦ä½¿ç”¨çš„è®­ç»ƒé›†ã€éªŒè¯é›†å’Œè¯„æµ‹é›†ã€‚
2. ç›®æ ‡åŸºç¡€æ¨¡å‹
3. å¾®è°ƒç­–ç•¥ï¼Œå¦‚å…¨å¾®è°ƒã€è½»é‡çº§å¾®è°ƒã€‚
4. è¶…å‚æ•°ï¼Œå¦‚å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€è®­ç»ƒè½®æ•°ç­‰ã€‚
5. åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼Œå›ºå®šä¸€éƒ¨åˆ†ç°æœ‰æ¨¡å‹å‚æ•° æˆ–è€… å…¨éƒ¨ä¿®æ”¹è®­ç»ƒã€‚
6. è¿›è¡Œå¾®è°ƒè®­ç»ƒ
7. æ¨¡å‹è¯„ä¼°å’Œè°ƒä¼˜ï¼ŒåŒ…å«äº†ä¸“ä¸šèƒ½åŠ›æµ‹è¯•å’Œé€šè¯†èƒ½åŠ›æµ‹è¯•ã€‚

- <font color='red'>ä¸“ä¸šèƒ½åŠ›æµ‹è¯•: å­¦ä¹  $X$ å†…å®¹ï¼Œè€ƒ $X$ å†…å®¹</font>ã€‚ä¾§é‡äºè€ƒå¯Ÿå¯¹**ä¸“ä¸šå†…å®¹çš„æŒæ¡**ï¼Œä¸»è¦åœ¨å¾®è°ƒé˜¶æ®µè¿›è¡Œï¼ŒéªŒè¯å¾®è°ƒæ•ˆæœã€‚
- <font color='red'>é€šè¯†èƒ½åŠ›æµ‹è¯•: å­¦ä¹  $X$ å†…å®¹ï¼Œè€ƒ $X'$ å†…å®¹</font>ã€‚ä¾§é‡äºè€ƒå¯Ÿå†…å®¹å¯¹**é€šç”¨èƒ½åŠ›çš„æå‡**ï¼Œå¦‚è®°å¿†åŠ›ã€é˜…è¯»ç†è§£ã€é€»è¾‘æ¨ç†ç­‰ã€‚ä¸»è¦åœ¨é¢„è®­ç»ƒé˜¶æ®µè¿›è¡Œï¼ŒéªŒè¯è®­ç»ƒæ•ˆæœï¼›å¾®è°ƒé˜¶æ®µä¸»è¦æ˜¯éªŒè¯ï¼Œä¸“ä¸šåº¦çš„æå‡æ²¡æœ‰å¾ˆä¸¥é‡çš„å½±å“æ¨¡å‹çš„åŸºç¡€èƒ½åŠ›ã€‚

8. æµ‹è¯•æ¨¡å‹æ€§èƒ½
9. æ¨¡å‹éƒ¨ç½²å’Œåº”ç”¨

# å¾®è°ƒå®éªŒ

Baichuan2 çš„å®˜æ–¹ Readme æä¾›äº†å¾®è°ƒçš„æ ·ä¾‹ï¼Œå› æ­¤ç¬¬ä¸€æ­¥å…ˆæŒ‰ç…§æ•™ç¨‹ï¼Œè·‘é€šæ ·ä¾‹ï¼ˆå®é™…ä¸Šä¹Ÿå¡åœ¨äº†ç¬¬ä¸€æ­¥ ğŸ˜­ï¼‰ã€‚

```
source load_torch2.1_py3.sh
# 1. å®‰è£…ç¯å¢ƒï¼ŒåŒ…æ‹¬ DeepSpeed
cd LLM/Baichuan2/fine-tune/
pip3 install -r requirements.txt
## torch å¯èƒ½è¢«è¦†ç›–ï¼Œé‡æ–°å®‰è£…
pip3 install /public/software/apps/DeepLearning/whl/dtk-23.10/pytorch/torch2.1/torch-2.1.0a0+git793d2b5.abi0.dtk2310-cp38-cp38-manylinux2014_x86_64.whl

# 2. DeepSpeed è„šæœ¬
vi fine_tune_train.sh
''' æ–‡ä»¶å†…å®¹
hostfile=""
# deepspeed
# --num_gpusï¼Œä¸è®¾ç½®é»˜è®¤ä¼šç”¨å¯è§çš„æ‰€æœ‰GPUï¼›
# --data_pathï¼Œæ•°æ®é›†è·¯å¾„ï¼›
# --model_name_or_pathï¼Œæ¨¡å‹è·¯å¾„ï¼›
# --output_dirï¼Œè¾“å‡ºè·¯å¾„ï¼›
# --tf32ï¼Œé NVIDIA çš„ GPUï¼Œæš‚æ—¶å…ˆè®¾ç½® False
deepspeed --hostfile=$hostfile fine-tune.py  \
    --report_to "none" \
    --data_path $1 \
    --model_name_or_path $2 \
    --output_dir $3 \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 False \
    --use_lora False
'''
chmod 764 fine_tune_train.sh

# 3. ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 16 --gres=dcu:2
salloc -p ${partition} -N 1 -n 16 --gres=dcu:2
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/Baichuan2/fine-tune/
./fine_tune_train.sh "data/belle_chat_ramdon_10k.json" "../models/Baichuan2-7B-Chat" "output"
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

è¿è¡Œ DeepSpeed æŒ‡ä»¤åï¼Œå¤§æ¦‚ç­‰ 1 åˆ†é’Ÿï¼Œé¡µé¢ä¸Šå¼€å§‹æœ‰å†…å®¹ä¸æ–­è¾“å‡ºã€‚ç„¶åæ¥ç€å‡ºç°æŠ¥é”™ï¼Œå†…å®¹ä¸ºæ˜¾å­˜ä¸è¶³ï¼ˆç›®å‰å¹³å°ä¸Š**å…è´¹**çš„ DCU çš„æ˜¾å­˜çº¦ä¸º **16G**/ä¸ªï¼‰ã€‚

![](https://files.mdnice.com/user/44560/49e91016-8f6b-45b8-ba73-88b42a16185f.png)

è¯¢é—® GPTï¼ŒæŸ¥æ‰¾è§£å†³æ–¹æ¡ˆå¦‚ä¸‹:

![](https://files.mdnice.com/user/44560/8d80d53d-e958-4872-abff-ba6f9b585ea6.png)

## æ•°æ®å¹¶è¡Œ

è¿›ä¸€æ­¥è¯¢é—® GPTï¼Œå¹¶å°è¯•åœ¨ <font color='red'>batch_size</font> çš„é…ç½®ä¸Šè¿›è¡Œå°è¯•ã€‚

![](https://files.mdnice.com/user/44560/f7c3bd77-de6e-431c-ac8f-7de7705bd002.png)

é€šè¿‡å°† batch_size è°ƒæ•´ä¸º 8ã€4ã€1ï¼Œä»¥åŠ DCU ä¹Ÿå°è¯•è°ƒæ•´ä¸º 2ã€3ã€4 ä¸ªï¼Œé—æ†¾çš„æ˜¯ç»“æœå‡ä¸º OOMï¼ˆout of memoryï¼‰ï¼Œåªèƒ½ç»§ç»­æ‰¾åˆ«çš„æ–¹æ¡ˆã€‚

å¦ä¸€æ–¹é¢ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„**æœ€ç®€æ•°æ®é›†**è¿›è¡Œæµ‹è¯•ã€‚

```
vi LLM/Baichuan2/fine-tune/data/test.json
''' æ–‡ä»¶å†…å®¹
[{
        "id": "27684",
        "conversations": [
            {
                "from": "human",
                "value": "ä½ å¥½ï¼Œè¯·é—®ä½ èƒ½å¸®æˆ‘æŸ¥ä¸€ä¸‹æ˜å¤©çš„å¤©æ°”å—ï¼Ÿ\n"
            },
            {
                "from": "gpt",
                "value": "å½“ç„¶ï¼Œä½ åœ¨å“ªä¸ªåŸå¸‚å‘¢ï¼Ÿ\n"
            },
            {
                "from": "human",
                "value": "æˆ‘åœ¨ä¸Šæµ·ã€‚\n"
            },
            {
                "from": "gpt",
                "value": "å¥½çš„ï¼Œæ ¹æ®å¤©æ°”é¢„æŠ¥ï¼Œæ˜å¤©ä¸Šæµ·å¤šäº‘è½¬é˜´ï¼Œæ°”æ¸©åœ¨20åˆ°25æ‘„æ°åº¦ä¹‹é—´ã€‚éœ€è¦æˆ‘å¸®ä½ æŸ¥è¯¢å…¶ä»–ä¿¡æ¯å—ï¼Ÿ"
            }
        ]
  }]
'''
```

åŒæ ·çš„ï¼Œç»“æœä¹Ÿæ˜¾ç¤º OOM çš„æŠ¥é”™ï¼Œå¯ä»¥å°ç»“ï¼Œæ•°æ®å±‚é¢ä¸Šçš„ä¼˜åŒ–æš‚æ—¶æ•ˆæœä¸å¤§ã€‚å†å›å¤´æ¥è¿›è¡Œç†è®ºåˆ†æï¼Œ7B çš„æ¨¡å‹ï¼Œ<font color='red'>ä»…åŠ è½½å’Œå­˜å‚¨å‚æ•°ï¼ŒåŸºæœ¬å°±æ¶ˆè€—äº† 10G å·¦å³çš„æ˜¾å­˜</font>ï¼Œè®­ç»ƒæœ¬èº«ä¹Ÿä¼šæœ‰ä¸´æ—¶å­˜å‚¨çš„æ¶ˆè€—ï¼Œå› è€Œç›¸æ¯”èµ·æ¥ï¼Œæ•°æ®é›†åº”è¯¥ä¸æ˜¯ä¸»è¦å½±å“ç‚¹ã€‚

## æ¨¡å‹å¹¶è¡Œ

è¯¢é—® GPT æ¨¡å‹å¹¶è¡Œçš„å†…å®¹ï¼Œå¯çŸ¥ç›®å½•ä¸‹çš„ **ds_config.json å³ä¸º DeepSpeed çš„é…ç½®æ–‡ä»¶**ã€‚

![](https://files.mdnice.com/user/44560/ae012d65-be81-415a-a287-12a80349e3e5.png)

å®éªŒé‡‡å‘åï¼Œå‘ç° GPT æ‰€è¯´çš„ partition_weights ç­‰é…ç½®å…¶å®å¹¶ä¸æ”¯æŒï¼ŒDeepSpeed ä¸»è¦æ˜¯ä½¿ç”¨äº† <font color='red'>ZeROï¼ˆZero Redundancy Optimizerï¼‰é›¶å†—ä½™ä¼˜åŒ–å™¨</font>æ¥å‡å°‘æ˜¾å­˜æ¶ˆè€—ã€‚

```
# é›¶ä¼˜åŒ–é…ç½®ï¼Œé˜¶æ®µ3 + å¸è½½
cd LLM/Baichuan2/fine-tune
vi ds_config.json
''' æ–‡ä»¶å†…å®¹
...
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },
'''
vi fine_tune_train.sh
''' æ–‡ä»¶å†…å®¹
...
    --num_train_epochs 1 \
    --per_device_train_batch_size 4 \
    --logging_steps 4 \
    --bf16 False \
'''

# ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 16 --gres=dcu:2
salloc -p ${partition} -N 1 -n 16 --gres=dcu:2
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/Baichuan2/fine-tune
./fine_tune_train.sh "data/test.json" "../models/Baichuan2-7B-Chat" "output"
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

è¿è¡Œåï¼Œä¼¼ä¹æ²¡æœ‰å‡ºç° OOM æŠ¥é”™ï¼Œä½†å‘ç°äº†æ–°çš„å¼‚å¸¸ã€‚

![](https://files.mdnice.com/user/44560/c39b8170-28ee-4815-a2d5-a02134419b34.png)

æŸ¥çœ‹ lib ç›®å½•ä¸‹çš„ torch æ–‡ä»¶å¤¹ï¼Œæœ€ç»ˆæ‰¾åˆ° version.pyã€‚è¯¥å¹³å°çš„ torch åŒ…çš„**cuda å€¼ä¸º None**ï¼Œè¿›è€Œå¯¼è‡´å¤–å±‚è°ƒç”¨æŠ¥é”™ï¼ˆåˆ°å“ªéƒ½æ˜¯ç†Ÿæ‚‰çš„ NPE é—®é¢˜ ğŸ˜­ï¼‰ã€‚

![](https://files.mdnice.com/user/44560/dcb59a1a-a2e0-4db5-bcfd-1b6695d4a6b5.png)

æŠ±æœ‰ä¸€ä¸ä¾¥å¹¸ï¼Œæš‚æ—¶ä¸æ‰“ç®—æ›´æ”¹æºç ï¼Œç»§ç»­æ¢è®¨åˆ«çš„è§£å†³æ–¹æ¡ˆã€‚

## LoRA è½»é‡çº§å¾®è°ƒ

æŒ‰ç…§æ•™ç¨‹ï¼ŒBaichuan2 çš„å¾®è°ƒä¹Ÿæ”¯æŒäº† <font color='red'>LoRAï¼ˆLow-Rank Adaptation of Large Language Modelsï¼‰</font>æŠ€æœ¯ï¼Œå› æ­¤æ‰“ç®—è¯•ä¸€æ³¢ã€‚

```
source load_torch2.1_py3.sh
# 1. å®‰è£…ç¯å¢ƒï¼Œpeft
pip3 install peft

# 2. DeepSpeed è„šæœ¬
cd LLM/Baichuan2/fine-tune/
vi fine_tune_train.sh
''' æ–‡ä»¶å†…çš„å†…å®¹
...
  --use_lora True
'''

# 3. ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 16 --gres=dcu:2
salloc -p ${partition} -N 1 -n 16 --gres=dcu:2
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/Baichuan2/fine-tune
set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32
./fine_tune_train.sh "data/test.json" "../models/Baichuan2-7B-Chat" "output"
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

ä»ç»“æœä¸Šæ¥çœ‹ï¼Œå°½ç®¡è§„é¿äº† OOM çš„é—®é¢˜ï¼Œä½†é‡åˆ°äº†ä¸€æ ·çš„æŠ¥é”™ï¼Œå³ torch åŒ…ä¸å…¶ä»–å·¥å…·ä¸å…¼å®¹ã€‚

![](https://files.mdnice.com/user/44560/c27edcad-7361-41b4-9fd9-74284ec624ae.png)

## LLaMA Factory

https://github.com/hiyouga/LLaMA-Factoryï¼Œæ— å¥ˆä¹‹ä¸‹ï¼Œå°ç‹—å±æ„å¤–æ‰¾åˆ°äº†ä¸€ä¸ªæ–°çš„å¹³å°ï¼Œå¸®å¿™**é›†æˆäº†é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ç­‰æ“ä½œ**ï¼ŒåŒæ—¶çœ‹æŠ¥å‘Šä¹Ÿæœ‰çœæ˜¾å­˜ã€çœæ—¶é—´çš„æ•ˆæœï¼Œå› è€Œæ‰“ç®—è¯•ä¸€è¯•ã€‚

```
source load_torch2.1_py3.sh
# 1. å®‰è£…ç¯å¢ƒ
cd LLM
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip3 install -r requirements.txt

# 2. è®¾ç½®æŒ‡ä»¤
vi sft_baichuan.sh
''' æ–‡ä»¶å†…å®¹
# ä¸ä½¿ç”¨ DeepSpeed æ—¶ï¼Œä¸ºå•æœºå•å¡
CUDA_VISIBLE_DEVICES=0 python3 src/train_bash.py \
    --stage sft \
    --do_train \
    --model_name_or_path ../Baichuan2/models/Baichuan2-7B-Chat \
    --dataset alpaca_gpt4_en \
    --template default \
    --finetuning_type lora \
    --lora_target W_pack \
    --output_dir "output" \
    --overwrite_cache \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 4 \
    --lr_scheduler_type cosine \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate 5e-5 \
    --num_train_epochs 3.0 \
    --plot_loss \
    --fp16
'''
chmod 764 sft_baichuan.sh

# 3. ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 8 --gres=dcu:1
salloc -p ${partition} -N 1 -n 8 --gres=dcu:1
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/LLaMA-Factory
./sft_baichuan.sh
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

åŒæ ·çš„ï¼Œè™½ç„¶æ²¡æœ‰ OOM çš„æŠ¥é”™ï¼Œä½†ä¹Ÿè¿˜æ˜¯é‡åˆ°äº†å…¼å®¹æ€§é—®é¢˜ã€‚

![](https://files.mdnice.com/user/44560/828632e3-fe97-4bdc-8c0c-8c2230495737.png)

# å…¼å®¹æ€§é—®é¢˜å¤„ç†

æ—¢ç„¶å¤šæ¬¡å°è¯•éƒ½æ— æ³•è§„é¿å…¼å®¹æ€§é—®é¢˜ï¼Œé‚£å°±åªèƒ½ç€æ‰‹å¤„ç†äº†ã€‚

é¦–å…ˆï¼Œæ˜ç¡®é—®é¢˜ä¸º: <font color='red'>DeepSpeedã€LoRAã€xFormers ç­‰å·¥å…·ï¼Œä¸ AMD æ˜¾å¡çš„ ROCm ç³»ç»Ÿå­˜åœ¨å±€éƒ¨çš„ä¸å…¼å®¹</font>ã€‚

è¿›ä¸€æ­¥ç”¨å…³é”®è¯ "xxx for rocm" è¿›è¡Œè°·æ­Œæœç´¢ï¼ŒåŸºæœ¬ä¹Ÿéƒ½èƒ½æ‰¾åˆ°ä¸€äº›å…¼å®¹æ–¹æ¡ˆï¼Œæˆ–è€…æ˜¯ AMD å®˜æ–¹ä¹Ÿä¼š fork é¡¹ç›®ä¹‹åè¿›è¡Œé€‚é…ã€‚

## DeepSpeed for ROCm + Baichuan2-fine-tune

DeepSpeed çš„å…¼å®¹ç­–ç•¥ä¸»è¦æ˜¯ï¼Œ<font color='red'>ç›´æ¥ä¿®æ”¹æºç ï¼Œè·³è¿‡éªŒè¯</font>ï¼›æ¥ç€ä½¿ç”¨ Baichuan2 è‡ªèº«çš„å¾®è°ƒä»£ç è¿›è¡Œå®éªŒã€‚

```
source load_torch2.1_py3.sh
# 1. deepspeed for rocmï¼Œhttps://github.com/microsoft/DeepSpeed/issues/3091
# ä¿®æ”¹æºç ï¼Œè·³è¿‡éªŒè¯
vi ~/miniconda3/envs/torch2.1_dtk23.10_py3.8/lib/python3.8/site-packages/deepspeed/ops/op_builder/builder.py
''' æ–‡ä»¶å†…å®¹
...
def assert_no_cuda_mismatch(name=""):
    # ROCM å¹³å°ï¼Œè·³è¿‡éªŒè¯
    if OpBuilder.is_rocm_pytorch():
        return True
    cuda_major, cuda_minor = installed_cuda_version(name)
'''
# 2. lora å®Œæˆé€‚é…å‰ï¼Œå…³é—­ lora
vi ~/LLM/Baichuan2/fine-tune/fine_tune_train.sh
''' æ–‡ä»¶å†…å®¹
...
  --use_lora False
'''

# 3. ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 16 --gres=dcu:2
salloc -p ${partition} -N 1 -n 16 --gres=dcu:2
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/Baichuan2/fine-tune
./fine_tune_train.sh "data/test.json" "../models/Baichuan2-7B-Chat" "output"
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

ç»“æœå‘ç°ä¸å…¼å®¹çš„ç¯èŠ‚å·²ç»è·³è¿‡å»äº†ï¼Œä½†æ˜¯æ¥ä¸‹æ¥åˆé‡åˆ°äº† OOM çš„é—®é¢˜ã€‚å› æ­¤ï¼Œè¿˜å¾—å†å€ŸåŠ© LoRA çš„ä¼˜åŒ–ã€‚

## LoRA for ROCm + LLaMA-Factory

LoRA çš„å…¼å®¹ç­–ç•¥ä¸»è¦æ˜¯ï¼Œ<font color='red'>åº•å±‚çš„ bitsandbytes ä½¿ç”¨ä½ç‰ˆæœ¬ï¼Œä¸ä¸¥æ ¼è¦æ±‚æ£€æµ‹åˆ° NVIDIA çš„ GPU</font>ï¼Œå¸¦æ¥çš„æ½œåœ¨é—®é¢˜å¯èƒ½æ˜¯é‡åŒ–è¿‡ç¨‹å®é™…ä½¿ç”¨ CPU è¿›è¡Œæ“ä½œï¼›æ¥ç€ä½¿ç”¨ LLaMa-Factory çš„è®­ç»ƒæ¡†æ¶è¿›è¡Œå®éªŒã€‚

```
source load_torch2.1_py3.sh
# 1. LoRA for rocmï¼Œhttps://github.com/oobabooga/text-generation-webui/issues/3259
# ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬çš„ bitsandbytes
pip3 uninstall bitsandbytes
pip3 install bitsandbytes==0.38.1

# 2. ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 8 --gres=dcu:1
salloc -p ${partition} -N 1 -n 8 --gres=dcu:1
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/LLaMA-Factory
./sft_baichuan.sh
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

ç»“æœä¼šå‘ç°ï¼Œå‡ºç°äº† <font color='red'>xFormers ç›¸å…³çš„å…¼å®¹æ€§æŠ¥é”™</font>ã€‚

![](https://files.mdnice.com/user/44560/f5ae7d9e-ddd8-4025-94d9-1ed28482ba7f.png)

æ¥ä¸‹æ¥ï¼ŒBaichuan2 çš„é…ç½®ä¸­å¼€å¯ LoRAï¼Œä¹Ÿä¼šèµ°åˆ° xFormers çš„å…¼å®¹æ€§æŠ¥é”™è¿™ã€‚

![](https://files.mdnice.com/user/44560/9026f278-a31b-4325-9cec-e4bf4b386e8a.png)

## xFormers for ROCm

æ€»ä½“æ€è·¯æ˜¯ç ”ç©¶å¹¶ä½¿ç”¨ AMD å®˜æ–¹çš„é€‚é…ç‰ˆæœ¬ï¼Œhttps://github.com/ROCm/xformersã€‚å…·ä½“ç»†èŠ‚ï¼Œå°±ä¸‹æ¬¡å†è¯´å§ã€‚

![](https://files.mdnice.com/user/44560/e85f4e64-c2dd-43c6-adcc-355b53683ccf.png)

# æ€» ç»“

ä¸»è¦é¢ä¸´çš„å›°éš¾:

- GPU çš„<font color='red'>æ˜¾å­˜è¾ƒå°</font>ï¼Œä»… 16 Gã€‚
- é NVIDIA çš„ GPUï¼ˆæ¨æµ‹æ˜¯ AMD-ROCmï¼‰ï¼Œä»¥åŠå¯¹åº”çš„ pytorchï¼Œè·Ÿ DeepSpeedã€LoRAã€xFormers ç­‰å¸¸ç”¨å·¥å…·çš„<font color='red'>ä¸å…¼å®¹</font>ã€‚

ä¸»è¦è§£å†³æ–¹æ¡ˆ:

- <font color='red'>é’ˆå¯¹æ˜¾å­˜è¾ƒå°ï¼Œä½¿ç”¨ LoRAã€ZeRO ç­‰å¾®è°ƒæ–¹æ¡ˆï¼ŒèŠ‚çœç©ºé—´</font>ã€‚
- é’ˆå¯¹ä¸å…¼å®¹ï¼Œé€æ­¥å¤„ç†ï¼Œç›®å‰å·²ç»å®Œæˆäº†<font color='red'> DeepSpeedã€LoRAï¼ˆbitsandbytesï¼‰çš„é€‚é…</font>ã€‚

ä¸‹ä¸€æ­¥è®¡åˆ’:

- è§£å†³ xFormers ä¸å…¼å®¹çš„é—®é¢˜ï¼Œå®Œæˆå•æ ·ä¾‹å¾®è°ƒå®éªŒã€‚
- é€‰æ‹©åˆé€‚çš„æ•°æ®é›†ï¼Œè¿›è¡Œä¸€æ¬¡å¾®è°ƒå®æ“ã€‚
