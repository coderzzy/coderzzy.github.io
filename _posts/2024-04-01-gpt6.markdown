---
layout: post
title: å¤§æ¨¡å‹ï¼Œå°æ¢ç´¢ â€”â€” åœ¨ 16G çš„ AMD ä¸Šæå¾®è°ƒæœ‰å¤šä½œæ­»ï¼Ÿï¼ˆå‡ºå‘ç¯‡ï¼‰
toc:  true
author: å°ç‹—å±
tags: [GPT-Explore]
css:
  - "assets/markdown.css"
---

å¾®ä¿¡å…¬ä¼—å·å†…å®¹åœ°å€: 

> å¾®è°ƒå®æ“: æ•°æ®é›†ã€è¶…å‚æ•°ã€æ¨¡å‹ç»“æ„ï¼Œå’Œè¯„æµ‹æŒ‡æ ‡ã€‚

æ€»çš„æ¥è¯´ï¼Œæœ¬æ¬¡å®æ“çš„æ€è·¯å¦‚ä¸‹ï¼š

1. **æ•°æ®**é˜¶æ®µ: é€‰å®šä¸šåŠ¡åœºæ™¯ï¼Œæ‰¾å¯»æ•°æ®é›†ã€‚
2. **çˆ¬å¡**é˜¶æ®µ: é€‰å®šæ¨¡å‹ã€å›ºå®šåŸºæœ¬è®­ç»ƒè¶…å‚æ•°ï¼Œ**å¢åŠ æ•°æ®é‡**ï¼Œè¾¾åˆ°åˆæ­¥æ•ˆæœã€‚
3. **è°ƒå‚**é˜¶æ®µ: é€‰å®šæ¨¡å‹**è¯„æµ‹æŒ‡æ ‡**ï¼Œå›ºå®šæ•°æ®ï¼ŒA/B Test è°ƒä¼˜**è¶…å‚æ•°**ã€‚
4. **å¯¹æ¯”**é˜¶æ®µ: é€‰å®šæ¨¡å‹è¯„æµ‹æŒ‡æ ‡ï¼Œå›ºå®šæ•°æ®ã€è¶…å‚æ•°ï¼Œå¯¹æ¯”**ä¸åŒæ¨¡å‹**ã€‚

# æ•°æ®é˜¶æ®µ

æ¥æº: https://tianchi.aliyun.com/competition/entrance/531904/information

![](https://files.mdnice.com/user/44560/fbeacf2f-dec4-41fc-b39a-46b463a20387.png)

åˆæ­¥é¢„è§ˆå¦‚ä¸‹ï¼Œä¸€å…± 5000 æ¡æ•°æ®:

![](https://files.mdnice.com/user/44560/1250e6ca-6f12-4c21-85d0-2fff573312dc.png)

ç”¨æˆ·é—®é¢˜å’Œç­”æ¡ˆåˆ—è‡ªç„¶å½¢æˆäº† Q&A çš„å½¢å¼ï¼Œæ— éœ€è¿›è¡Œè¿‡å¤šè½¬æ¢å¤„ç†ï¼›åŒæ—¶ï¼Œå®˜æ–¹ç½‘ç«™çš„æ•°æ®é›†ï¼Œä¹Ÿå‡å°‘äº†**æ•°æ®æ¸…æ´—**ã€æ£€éªŒ**æ ‡æ³¨è´¨é‡**ç­‰æ“ä½œçš„è´Ÿæ‹…ï¼›æ›´ä¸ºé‡è¦çš„è¿˜æ˜¯ï¼Œ**ä¾¿äºéªŒè¯**:

- å…¶ä¸€ï¼Œæ¨¡å‹æœ¬èº«åº”è¯¥ä¹‹å‰æ²¡æœ‰å­¦ä¹ è¿‡ç±»ä¼¼çŸ¥è¯†ã€‚
- å…¶äºŒï¼Œéš¾åº¦é€‚ä¸­ï¼Œç›¸æ¯”äºç”Ÿæˆå‹ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ›´æ¥è¿‘äºåˆ†ç±»ã€‚
- å…¶ä¸‰ï¼Œç­”æ¡ˆå®¢è§‚ï¼Œè¾ƒå¥½éªŒè¯ç»“æœã€‚

å¯ä»¥å°†å…¶è½¬åŒ–æˆ telecom_train_5000.jsonï¼Œ

```
[
  {
    "instruction": "å›ç­”ä¸­å›½ç”µä¿¡æ‰‹æœºç”¨æˆ·çš„é—®é¢˜,9å…ƒç™¾åº¦ä¸“å±å®šå‘æµé‡åŒ…å¦‚ä½•å–æ¶ˆ,åº”è¯¥æ€ä¹ˆåšï¼Ÿ",
    "input": "",
    "output": "å–æ¶ˆæ–¹å¼_68"
  },
  {
    "instruction": "å›ç­”ä¸­å›½ç”µä¿¡æ‰‹æœºç”¨æˆ·çš„é—®é¢˜,ä½ å‘Šè¯‰æˆ‘7å¤©5gè§†é¢‘ä¼šå‘˜æµé‡åŒ…æ€ä¹ˆå¼€é€šï¼Œå¤šå°‘é’±,åº”è¯¥æ€ä¹ˆåšï¼Ÿ",
    "input": "",
    "output": "ä¸šåŠ¡ç®€ä»‹_111|9.9|11.9|å¼€é€šæ–¹å¼_98|ä¸šåŠ¡ç®€ä»‹_109|å¼€é€šæ–¹å¼_97"
  },
  ...
]
```

å°†æ•°æ®æ›´æ–°åˆ° LLaMA Factory æ¡†æ¶ä¸­ï¼Œ

```
vi LLM/LLaMA-Factory/data/dataset_info.json
''' æ–‡ä»¶å†…å®¹
  ...
"telecom_train_5000": {
    "file_name": "telecom_train_5000.json",
    "columns": {
      "prompt": "instruction",
      "query": "input",
      "response": "output"
    }
  },
'''
```

åŒæ ·çš„æ“ä½œï¼Œå¯ä»¥å‡†å¤‡å¥½ telecom_train_400ã€telecom_train_100ã€telecom_test_100 ç­‰æ•°æ®é›†å¤‡ç”¨ï¼ˆæˆªå–æ•°æ®æ—¶éœ€è¦è€ƒè™‘**æ•°æ®å¹³è¡¡**ï¼Œå³ä¸åŒè§„æ¨¡çš„æ•°æ®é›†å†…ï¼Œå„ç±»åˆ«çš„é—®é¢˜æ•°é‡æ¯”ä¾‹åº”å°½é‡ä¿æŒä¸€è‡´ï¼‰ã€‚

# çˆ¬å¡é˜¶æ®µ

é¦–å…ˆï¼Œæˆ‘ä»¬é€‰å®šæ¨¡å‹ gemma-2b (å‚æ•°é‡ç›¸å¯¹è¾ƒå°‘ï¼Œå ç”¨æ˜¾å­˜å°‘ï¼Œé€‚åˆå®éªŒ)ï¼Œå¹¶ä¸”å…ˆæé—®ï¼Œçœ‹æ¨¡å‹æœ¬èº«æ˜¯å¦å·²ç»ä¼šäº†ã€‚

```
## è°ƒç”¨æ¨¡å‹ï¼Œå®éªŒç»“æœ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 8 --gres=dcu:1
salloc -p ${partition}$ -N 1 -n 8 --gres=dcu:1
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/LLaMA-Factory
# Factory è®­ç»ƒï¼Œå› æ­¤ä¹Ÿå¾—ä½¿ç”¨ Factory æ¨ç†ï¼ˆä¿æŒ template ä¸€è‡´ï¼‰
CUDA_VISIBLE_DEVICES=0 python3 src/cli_demo.py --model_name_or_path ../gemma/models/gemma-2b --template default
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

åˆæ­¥çœ‹èµ·æ¥ï¼Œæ¨¡å‹æœ¬èº«å¹¶ä¸çŸ¥é“æ€ä¹ˆå›ç­”ç›¸å…³é—®é¢˜ã€‚

![](https://files.mdnice.com/user/44560/71cf5bf0-6c41-458a-b971-231804cad0c4.png)

## è°ƒæ•´åŸºæœ¬çš„ LoRA å‚æ•°

å¯ä»¥åœ¨ LLaMA-Factory/src/llmtuner/hparams/finetuning_args.py æ–‡ä»¶ä¸­ï¼Œé€šè¿‡ LoraArguments æŸ¥çœ‹æ›´å¤šçš„å±æ€§é…ç½®ã€‚

![](https://files.mdnice.com/user/44560/343cb8ce-1138-487a-990c-0995e5f58c81.png)

å…·ä½“å‚æ•°çš„å«ä¹‰åç»­ä¼šè¿›ä¸€æ­¥å±•å¼€ï¼Œè¿™é‡Œå…ˆé ç›´è§‰è®¾ç½®ä¸€äº›å€¼ã€‚

```
vi LLM/LLaMA-Factory/sft_single.sh
''' æ–‡ä»¶å†…å®¹
  ...
    --finetuning_type lora \
    --lora_target $3 \
    --lora_alpha 256 \
    --lora_rank 128 \
    --lora_dropout 0.1 \
    --loraplus_lr_ratio 1.0 \
    --loraplus_lr_embedding 1e-6 \
    --use_rslora \
    --use_dora \
    --create_new_adapter \
    --per_device_train_batch_size 8 \
    --gradient_accumulation_steps 8 \
    --lr_scheduler_type cosine \
    --learning_rate 5e-5 \
    --num_train_epochs 5.0 \
  ...
'''
```

## å¾®è°ƒï¼Œ400 æ ·æœ¬

å…ˆä½¿ç”¨å°‘é‡ 400 æ¡æ•°æ®è¿›è¡Œå°è¯•ï¼Œçœ‹æ˜¯å¦æœ‰æ•ˆã€‚

```
## ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œå¼€å§‹è¿è¡Œ
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 8 --gres=dcu:1
salloc -p ${partition} -N 1 -n 8 --gres=dcu:1
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/LLaMA-Factory
# å¾®è°ƒ
./sft_single.sh ../gemma/models/gemma-2b telecom_train_400 q_proj,v_proj,k_proj outputs/sft_output_gemma_20240328
  ...
# æŸ¥çœ‹æ–‡ä»¶å¤§å°
du -sh outputs/*
# æ¨ç†
CUDA_VISIBLE_DEVICES=0 python3 src/cli_demo.py --model_name_or_path ../gemma/models/gemma-2b --adapter_name_or_path outputs/sft_output_gemma_20240328 --template default --finetuning_type lora
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

å¾®è°ƒè¿‡ç¨‹å¦‚ä¸‹ï¼Œä¸»è¦å¯ä»¥çœ‹å‡ºä»¥ä¸‹æ•°æ®:

- æ¨¡å‹è®­ç»ƒçš„å‚æ•°çº¦ä¸º **2000w**ï¼Œçº¦ä¸º<font color='red'>æ€»å‚æ•°é‡çš„ 1%</font>ã€‚
- ä» **loss å€¼**æ¥çœ‹ï¼Œæœ€åä¸€æ¬¡çº¦ä¸º 0.6ï¼Œç›´è§‰ä¸Šæ¥çœ‹ï¼Œä»ç„¶è¾ƒå¤§ï¼Œæœ‰æå‡ç©ºé—´ã€‚
- æ¯ç§’è®­ç»ƒçš„æ ·æœ¬æ•°çº¦ä¸º 8 ä¸ªï¼Œæ‰€ä»¥æ€»è®­ç»ƒæ—¶é•¿çº¦ä¸º 400 \* 5 epoch / 8 = 250 ç§’ï¼Œå³ 4 åˆ†é’Ÿã€‚å¯ä»¥æ¨æ–­ï¼Œåœ¨ä¸è€ƒè™‘åˆ†å¸ƒå¼çš„æƒ…å†µä¸‹ï¼Œå®Œæ•´è®­ç»ƒ 5000 ä¸ªæ ·æœ¬çº¦éœ€è¦ 50 åˆ†é’Ÿã€‚

![](https://files.mdnice.com/user/44560/a85e4288-cd4b-4c09-9764-c31207aecc23.png)

å¯¹å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæé—®ï¼Œç»“æœå¦‚ä¸‹ã€‚çœ‹èµ·æ¥ï¼Œæ¨¡å‹å·²ç»<font color='red'>æœ‰æ‰€"è¿›æ­¥"</font>ã€‚

![](https://files.mdnice.com/user/44560/d0128763-0977-4b83-8580-7f45fe32952f.png)

## å¾®è°ƒï¼Œ5000 æ ·æœ¬

å…¶ä½™æ“ä½œå‡ä¸å˜ï¼Œä½¿ç”¨ telecom_train_5000 è¿›è¡Œå¾®è°ƒï¼Œæ€»å…±çº¦è€—æ—¶ 40 åˆ†é’Ÿå®Œæˆã€‚

æŸ¥çœ‹ loss å€¼æ›²çº¿ï¼Œæœ€ä½è¾¾åˆ° **0.3** å·¦å³ï¼Œè¾ƒä¹‹å‰æœ‰æ›´å¤šæå‡ã€‚

![](https://files.mdnice.com/user/44560/7dbc3014-1c34-405b-9830-48c9e14ce361.png)

è¿›è¡Œæé—®ï¼Œæ•ˆæœè¿›ä¸€æ­¥æå‡ï¼Œè™½ç„¶å…·ä½“çš„æ•°å­—æ²¡æœ‰ç­”å¯¹ ğŸ˜‚ï¼Œä½†æ€»çš„æ¥è¯´ï¼Œçˆ¬å¡å·²å®Œæˆã€‚

![](https://files.mdnice.com/user/44560/048bbbf7-062c-4072-aa9f-4c469c3572c9.png)

# è°ƒå‚é˜¶æ®µ

æ¥ä¸‹æ¥ï¼Œä¾¿æ˜¯è°ƒå‚äº†ã€‚

é¦–å…ˆï¼Œéœ€è¦é‡åŒ–è¯„æµ‹æŒ‡æ ‡ï¼Œä¸€æ–¹é¢æ˜¯ç”¨æ›´å¤šçš„å®¢è§‚è¯„ä»·ç»´åº¦æ¥ä»£æ›¿äººçš„ä¸»è§‚åˆ¤æ–­ï¼›å¦ä¸€æ–¹é¢ä¹Ÿæœ‰åˆ©äºè‡ªåŠ¨åŒ–ï¼Œæé«˜è°ƒå‚æ•ˆç‡ã€‚

## é‡åŒ–è¯„æµ‹æŒ‡æ ‡

```
## 1 å®‰è£…ç¯å¢ƒ
source load_torch2.1_py3.sh
pip3 install nltk jieba rouge-chinese jsonlines

## 2 é¢„æµ‹è„šæœ¬ï¼ŒåŒæ—¶è®¡ç®— BLEU å’Œ ROUGE
vi LLM/LLaMA-Factory/predict_single.sh
''' æ–‡ä»¶å†…å®¹
CUDA_VISIBLE_DEVICES=0 python3 src/train_bash.py \
    --stage sft \
    --do_predict \
    --model_name_or_path $1 \
    --adapter_name_or_path $2 \
    --dataset $3 \
    --template default \
    --finetuning_type lora \
    --output_dir $4 \
    --overwrite_output_dir \
    --per_device_eval_batch_size 1 \
    --max_samples 150 \
    --predict_with_generate \
    --fp16
'''
chmod 764 LLM/LLaMA-Factory/predict_single.sh

## 3 è¯„æµ‹è„šæœ¬ï¼Œç²¾å‡†ç‡å’Œå¬å›ç‡
vi LLM/LLaMA-Factory/predict_acc_rate.py
''' æ–‡ä»¶å†…å®¹
# -*- coding: utf-8 -*-
import jsonlines
import pandas as pd
import sys
# è·å–å‘½ä»¤è¡Œå‚æ•°
if len(sys.argv) != 2:
    print("Usage: python python.py path_to_jsonl_file")
    sys.exit(1)
jsonl_path = sys.argv[1]
# è¯»å– JSONL æ–‡ä»¶å¹¶è½¬æ¢ä¸º DataFrame
data = []
with jsonlines.open(jsonl_path, 'r') as reader:
    for line in reader:
        data.append(line)
df = pd.DataFrame(data)
# 1. æ–°å¢ä¸€åˆ—â€œcheckâ€
df['check'] = (df['label'] == df['predict']).astype(int)
# ç»Ÿè®¡checkç­‰äº1çš„å æ¯”
check_percentage = (df['check'] == 1).mean()
print("checkç­‰äº1çš„å æ¯”ï¼š", check_percentage)
# 2. æ–°å¢ä¸€åˆ—â€œlong answerâ€
df['long_answer'] = (df['label'].apply(len) > 10).astype(int)
# ç»Ÿè®¡åœ¨labelç­‰äº1çš„æ ·æœ¬ä¸­checkç­‰äº1çš„å æ¯”
check_percentage_in_long_answer = df[df['long_answer'] == 1]['check'].mean()
print("åœ¨labelç­‰äº1çš„æ ·æœ¬ä¸­checkç­‰äº1çš„å æ¯”ï¼š", check_percentage_in_long_answer)
'''

## 4 ç™»è¿œç¨‹èŠ‚ç‚¹ï¼Œè¿›è¡Œæµ‹è¯•
# ç”³è¯·èµ„æºï¼Œä¸€èˆ¬æ ¸å¡æ¯”ä¸º 8:1
whichpartition
  ...
# salloc -p kshdtest -N 1 -n 8 --gres=dcu:1
salloc -p ${partition} -N 1 -n 8 --gres=dcu:1
# æŸ¥çœ‹ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°èŠ‚ç‚¹å
squeue
  ...
# ç™»å½•åˆ°èŠ‚ç‚¹ä¸Š
ssh ${node_name}
# ä¸»æŒ‡ä»¤
source load_torch2.1_py3.sh
cd LLM/LLaMA-Factory
# è®­ç»ƒé›†ä¸Šé¢„æµ‹
./predict_single.sh ../gemma/models/gemma-2b outputs/sft_output_gemma_20240328 telecom_train_100 outputs/sft_predict_train_output_gemma_20240328
  ...
# è®­ç»ƒé›†çš„è¯„æµ‹
python3 predict_acc_rate.py outputs/sft_predict_train_output_gemma_20240328/generated_predictions.jsonl
  ...
# æµ‹è¯•é›†ä¸Šé¢„æµ‹
./predict_single.sh ../gemma/models/gemma-2b outputs/sft_output_gemma_20240328 telecom_test_100 outputs/sft_predict_test_output_gemma_20240328
  ...
# æµ‹è¯•é›†çš„è¯„æµ‹
python3 predict_acc_rate.py outputs/sft_predict_test_output_gemma_20240328/generated_predictions.jsonl
  ...
exit  # ç¬¬ä¸€ä¸ª exitï¼Œç™»å‡ºèŠ‚ç‚¹
exit  # ç¬¬äºŒä¸ª exitï¼Œé€€å‡ºä½œä¸š
```

å¯¹ BLEU å’Œ ROUGE çš„è®¡ç®—ï¼Œæœ‰å¦‚ä¸‹ç¤ºä¾‹ã€‚ç®€å•æ¥è¯´ï¼ŒBLEU ç±»ä¼¼äºç²¾ç¡®ç‡ï¼Œä»¥æ¨¡å‹ç»“æœä¸­çš„æ€»æ•°é‡ä¸ºåˆ†æ¯ï¼Œ<font color='red'>å¸Œæœ›æ¨¡å‹ç­”çš„å°½å¯èƒ½çš„å¯¹</font>ï¼›ROUGE ç±»ä¼¼äºå¬å›ç‡ï¼Œä»¥å‚è€ƒç»“æœä¸­çš„æ€»æ•°é‡ä¸ºåˆ†æ¯ï¼Œ<font color='red'>å¸Œæœ›æ¨¡å‹ç­”çš„å°½å¯èƒ½çš„å…¨</font>ã€‚

![](https://files.mdnice.com/user/44560/fd3870be-fda7-42c1-9961-5289702fdab0.png)

ç›¸å…³æŒ‡æ ‡ä»¥åŠæ•°æ®ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤º:

| æŒ‡æ ‡          | æŒ‡æ ‡å«ä¹‰                                                                                                       | å€¼-è®­ç»ƒé›†/% | å€¼-æµ‹è¯•é›†/% |
| ------------- | -------------------------------------------------------------------------------------------------------------- | ----------- | ----------- |
| BLEU-4        | å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œå°†æ¨¡å‹ç»“æœå’Œæ ‡ç­¾æŒ‰ 4-gram æ‹†åˆ†åï¼Œè®¡ç®—ç²¾ç¡®ç‡ï¼ˆ**æ¨¡å‹ç»“æœä¸ºåˆ†æ¯**ï¼Œå‘½ä¸­å€¼ä¸ºåˆ†å­ï¼‰ï¼›æ‰€æœ‰æ ·æœ¬å–å¹³å‡ã€‚ | 49.43       | 53.58       |
| ROUGE-1       | å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œå°†æ¨¡å‹ç»“æœå’Œæ ‡ç­¾æŒ‰ 1-gram æ‹†åˆ†åï¼Œè®¡ç®—å¬å›ç‡ï¼ˆ**æ ‡ç­¾ä¸ºåˆ†æ¯**ï¼Œå‘½ä¸­å€¼ä¸ºåˆ†å­ï¼‰ï¼›æ‰€æœ‰æ ·æœ¬å–å¹³å‡ã€‚     | 63.56       | 62.76       |
| ROUGE-2       | å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œå°†æ¨¡å‹ç»“æœå’Œæ ‡ç­¾æŒ‰ 2-gram æ‹†åˆ†åï¼Œè®¡ç®—å¬å›ç‡ï¼ˆ**æ ‡ç­¾ä¸ºåˆ†æ¯**ï¼Œå‘½ä¸­å€¼ä¸ºåˆ†å­ï¼‰ï¼›æ‰€æœ‰æ ·æœ¬å–å¹³å‡ã€‚     | 46.37       | 51.98       |
| ROUGE-L       | ç±»ä¼¼çš„ï¼Œè€ƒè™‘æœ€é•¿å…¬å…±å­åºåˆ—ï¼Œåè¿›è¡Œè®¡ç®—ã€‚                                                                       | 59.19       | 59.73       |
| å‡†ç¡®ç‡ Acc    | å¯¹æ‰€æœ‰æ ·æœ¬ï¼Œä¸ä»¥ n-gram è¿›è¡Œæ‹†åˆ†ï¼Œè€ƒè™‘**å®Œå…¨ä¸€è‡´**ï¼Œè®¡ç®—å‡†ç¡®ç‡ã€‚                                               | 19          | 24          |
| å¬å›ç‡ Recall | å¯¹æ‰€æœ‰æ ·æœ¬ï¼Œä¸ä»¥ n-gram è¿›è¡Œæ‹†åˆ†ï¼Œè€ƒè™‘**å®Œå…¨ä¸€è‡´**ï¼Œè®¡ç®—å¬å›ç‡ã€‚                                               | 13.79       | 21.74       |

åœ¨æœ¬æ¬¡ä»»åŠ¡ä¸­ï¼Œé€‰æ‹©è€ƒè™‘**å®Œå…¨ä¸€è‡´**çš„ Acc å’Œè€ƒè™‘**è¦†ç›–æ€§**çš„ ROUGE-1 ä½œä¸ºè¯„åˆ¤æ ‡å‡†ï¼Œè¿›è¡Œè°ƒå‚ã€‚

## LoRA å‚æ•°ç†è§£

LoRAï¼ˆLow-Rank Adaptation of Large Language Modelsï¼‰ï¼Œå¾®è½¯ç ”å‘çš„ä½ç§©è‡ªé€‚åº”æŠ€æœ¯ï¼Œæ—¨åœ¨ç”¨ä¸¤ä¸ªä½ç§©çŸ©é˜µæ›¿ä»£å¾…æ›´æ–°çš„æƒé‡çŸ©é˜µçš„å¢é‡ã€‚ç›¸å½“äºåœ¨å†»ç»“åŸæ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œ<font color='red'>åªè®­ç»ƒæ–°å¢çš„ç½‘ç»œå±‚å‚æ•°</font>ï¼Œè¿›è€Œå¤§å¤§å‡å°å¾®è°ƒçš„æˆæœ¬ã€‚

![](https://files.mdnice.com/user/44560/26ab4dc8-e1a5-43bb-8e0c-257e661f0343.png)

ç›¸å…³çš„å‚æ•°åŒ…æ‹¬:

- additional_target: é™¤äº† LoRA å±‚ä¹‹å¤–ï¼ˆå³é™¤äº†ä¸¤ä¸ªä½ç§©çŸ©é˜µï¼‰ï¼Œè¦è®¾ç½®ä¸ºå¯è®­ç»ƒå¹¶ä¿å­˜åœ¨æœ€ç»ˆæ£€æŸ¥ç‚¹ä¸­çš„æ¨¡å—åç§°ã€‚
- lora_alpha: çŸ©é˜µçš„æ ‡å®šå› å­ï¼Œå€¼è¶Šå¤§ï¼Œæ›´æ–°æƒé‡è¶Šç§¯æï¼›<font color='red'>ä¸€èˆ¬å»ºè®®ä¸º lora_rank çš„ 2 å€</font>ã€‚
- lora_rank: çŸ©é˜µçš„ç§©ï¼Œä¸€èˆ¬ä¸º 32ã€128ã€256ã€‚
- lora_dropout: dropout ç‡ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
- loraplus_lr_ratio: å­¦ä¹ ç‡æ¯”ç‡ï¼ˆlr_B / lr_Aï¼‰ã€‚
- loraplus_lr_embedding: LoRA åµŒå…¥å±‚çš„å­¦ä¹ ç‡ã€‚
- use_rslora: æ˜¯å¦ä½¿ç”¨<font color='red'>ç§©ç¨³å®š</font>çš„ LoRAï¼Œå³ rsLoRAï¼ˆç¼©æ”¾å› å­ $\gamma = \frac{\alpha}{\sqrt{r}}$ï¼‰ã€‚
- use_dora: æ˜¯å¦ä½¿ç”¨<font color='red'>æƒé‡åˆ†è§£</font>çš„ LoRA æ–¹æ³•ï¼ˆDoRAï¼‰ã€‚
- create_new_adapter: æ˜¯å¦åˆ›å»ºä¸€ä¸ªå…·æœ‰<font color='red'>éšæœºåˆå§‹åŒ–æƒé‡</font>çš„æ–°é€‚é…å™¨ã€‚
- lora_traget: ç”¨äºæŒ‡å®šåº”ç”¨ LoRA çš„<font color='red'>ç›®æ ‡æ¨¡å—</font>çš„åç§°ã€‚
  - ä½¿ç”¨ "all" è¡¨ç¤ºåº”ç”¨äºæ‰€æœ‰çº¿æ€§æ¨¡å—ã€‚
  - LLaMA: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  - ChatGLM: ["query_key_value", "dense", "dense_h_to_4h", "dense_4h_to_h"]
  - Baichuan: ["W_pack", "o_proj", "gate_proj", "up_proj", "down_proj"]
  - ...

## å®éªŒæŠ¥å‘Š

![](https://files.mdnice.com/user/44560/81870b01-7aea-4897-9747-a51e22009841.png)

æ€»çš„æ¥è¯´ï¼Œç»å†äº†ä»¥ä¸Šå®éªŒï¼Œåœ¨è¿è¥å•†çŸ¥è¯†æ•°æ®é›†å¾®è°ƒçš„åœºæ™¯ä¸‹ï¼Œæœ‰ä»¥ä¸‹ç»“è®º:

- lora_alphaã€lora_rankã€lora_target å’Œ use_rslora è¿™å››ä¸ªå‚æ•°å¯¹æ¨¡å‹ç»“æœå½±å“æ˜æ˜¾
  - lora_alpha å»ºè®®ä¸º lora_rank çš„ 2 å€ï¼Œ<font color='red'>lora_rank çš„æœ€ä¼˜å€¼ç›®å‰ä¸º 256</font>ã€‚
  - lora_targetï¼Œç›®å‰ç»“è®ºä¸º <font color='red'>qkvo > qkv = qv</font>ã€‚
  - use_rsloraï¼Œå³<font color='red'>ç§©ç¨³å®šçš„ LoRAï¼Œå¼€å¯åæ­£å‘æ•ˆæœæ˜æ˜¾</font>ã€‚
- æ¨¡å‹è®­ç»ƒå‚æ•°ã€è®­ç»ƒå adapter çš„å¤§å°ï¼Œè·Ÿ lora_alphaã€lora_rankã€lora_target å’Œ use_dora æœ‰å…³ã€‚

ç›®å‰çš„æœ€ä¼˜é…ç½®ä¸º:

```
lora_alpha: 512
lora_rank: 256
lora_dropout: 0.0
lora_target: q_proj, k_proj, v_proj, o_proj
loraplus_lr_ratio: 1.0
loraplus_lr_embedding: 1e-6
use_rslora: True
use_dora: True
create_new_adapter: True
```

ä½¿ç”¨è¯¥é…ç½®è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œå†æ¬¡å›ç­”ä¹‹å‰çš„é—®é¢˜ï¼Œç›®å‰å·²ç»<font color='red'>å®Œå…¨å›ç­”æ­£ç¡®</font> âœŒğŸ»ã€‚

![](https://files.mdnice.com/user/44560/1636bfde-90ab-4c64-bd41-0614cbaf1939.png)

